# Quotes Scraper

Этот проект представляет собой парсер для сайта по указанному в задании URL: [https://quotes.toscrape.com](https://quotes.toscrape.com).
Файл с JSON данными так же находится в репозитории проекта
Ссылка на репозиторий https://github.com/kvazymir1199/parser
## Описание функциональности

1. **Получение данных с сайта**: Реализована функция получения данных с использованием библиотеки `aiohttp`.
2. **Парсинг данных**: Данные парсятся с помощью библиотеки `BeautifulSoup`.
3. **Преобразование данных**: Данные преобразуются в удобные Python-объекты.
4. **Сохранение данных**: Данные сохраняются в требуемом формате (JSON).

## Асинхронный сбор данных

Сбор данных осуществляется по страницам в асинхронном режиме. Параметры количества страниц и одновременных запросов можно регулировать через глобальные переменные скрипта.

## Почему асинхронный подход?

Я выбрал асинхронный подход для решения данной задачи, потому что операции ввода/вывода требуют достаточно длительного времени для выполнения. Работа с сетевыми запросами как раз является такой задачей.

## Используемые библиотеки

- **BeautifulSoup**: Для работы с DOM HTML-страницы. Эта библиотека имеет актуальную документацию и регулярно обновляется.
- **aiohttp**: Клиент для выполнения асинхронных запросов к серверу.

## Запуск проекта через Docker

Клонируйте репозиторий и перейдите в него в командной строке:

```sh
git clone https://github.com/kvazymir1199/parser.git && cd parser
```
Выполните команду для сборки образа 

```sh
docker build -t parser .
```
Для запуска контейнера выполнить команду

```sh
docker run -v $(pwd):/app parser
```
## Запуск проекта через терминал

Клонируйте репозиторий и перейдите в него в командной строке:

```sh
git clone https://github.com/kvazymir1199/parser.git && cd parser
```

Разверните виртуальное окружение 
```sh
python -m venv venv
```

Установиту зависимости 
```sh
pip install -r requirements.txt
```
Запустите проект
```sh
python main.py
```
